# big-file 大文件上传

参考[请你实现一个大文件上传和断点续传](https://juejin.im/post/6844904046436843527#heading-6)

从零搭建前端和服务端，实现一个大文件上传和断点续传的 demo

前端：vue 

服务端：nodejs

## 起步
```
# 安装依赖
yarn
# 启动服务
yarn serve
# 启动前端
yarn start
```

### 思路

利用`Blob.prototype.slice` 方法将文件分成`n`个切片, 每个切片发送个上传请求, 

等所有请求完成, 再发送个合并请求, 通知服务端合并之前上传的切片

服务端接收这些切片,先缓存到一个文件夹中, 待接到合并请求后,

使用 nodejs 的 读写流（readStream/writeStream），将所有切片的流传输到最终文件的流里

合并完后删除缓存文件夹

## 版本

每个版本建立个独立分支, 方便按块学习

### 一. 初步完成文件切片上传

使用slice()将文件切片后使用Promise.all()分切片上传, 

服务端接收 使用multiparty 解析传过来的文件, 切片上传完后, 发送切片合并请求, 服务端合并切片, 完成这个流程

### 二. 基本进度条完成

引入element组件来做进度条展示

使用xhr.upload.onprogress 事件来监听每个切片上传进度情况, 根据每个进度和总的文件大小计算总进度

### 三. 使用hash 实现秒传

避免修改文件名后失去效果, 所以要根据文件内容生成 hash, 之后无论怎么修改文件名, 只要文件内容不变, 缓存都会有效

这里使用spark-md5实现生成文件内容hash值, 但读取文件内容计算hash非常耗时, 会引起ui阻塞,使页面假死, 这里使用web-worker 在 worker 线程计算 hash

在public放入spark-md5.min.js库, 新建hash.js文件用来生成hash, 点击上传时生成hash

把之前用文件名的替换成hash, 包括缓存切片文件夹名, 切片名, 合并文件名等

这样在前端发起上传请求时, 就可以根据hash判断该文件是否存在, 存在就直接返回, 无需再次上传

在发送上传请求前, 先发送一个校验请求, 校验文件是否存在, 存在就直接返回, 无需再次上传

